{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 快速使用手册"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"2\"\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看是否有GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") ##判断是否有gpu\n",
    "if torch.cuda.is_available():\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    \n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    #tf.set_random_seed(seed)\n",
    "seed_everything(2019)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 基本命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 224, 224]) torch.FloatTensor\n",
      "torch.Size([2, 3, 224, 224]) torch.FloatTensor\n",
      "torch.Size([2, 3, 224, 224])\n",
      "tensor([ 0.1459, -2.1029])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,224,224)\n",
    "print(x.size(),x.type())\n",
    "y = torch.randn(2,3,224,224)\n",
    "z = x+y\n",
    "\n",
    "print(z.size(),z.type())\n",
    "print(y.add_(x).size())\n",
    "print(y[1,1,1,:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor与numpy相互转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: torch.Size([5]) <class 'torch.Tensor'>\n",
      "b: (5,) <class 'numpy.ndarray'>\n",
      "b <class 'numpy.ndarray'>\n",
      "e <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor ->numpy\n",
    "a = torch.ones(5)\n",
    "print(\"a:\",a.size(),type(a))\n",
    "b = a.numpy()\n",
    "print('b:',b.shape,type(b))\n",
    "\n",
    "# numpy ->torch.Tensor\n",
    "e=torch.from_numpy(b)\n",
    "print('b',type(b))\n",
    "print('e',type(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor与cuda相互转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Tensor ->cuda \n",
    "x = torch.randn(2,3,224,224)\n",
    "y = torch.randn(2,3,224,224)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    x = x.to(device)\n",
    "    y = y.cuda()\n",
    "    x + y\n",
    "\n",
    "# cuda->torch.Tensor \n",
    "b = x.cpu()\n",
    "c = y.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor与Variable相互转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: <class 'torch.Tensor'> torch.Size([2, 3, 224, 224]) torch.FloatTensor\n",
      "c: torch.FloatTensor torch.Size([2, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor ->Variable\n",
    "from torch.autograd import Variable\n",
    "x = torch.randn(2,3,224,224)\n",
    "y = Variable(x)\n",
    "print('y:',type(y),y.size(),y.type())\n",
    "\n",
    "# Variable -> torch.Tensor\n",
    "c=y.data#通过 Variable.data 方法相当于将Variable中的torch.tensor 取出来\n",
    "print('c:',c.type(),c.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy与list相互转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: <class 'list'>\n",
      "g: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#  numpy -> list\n",
    "import numpy as np\n",
    "d = np.random.random((2,4))\n",
    "f1=d.tolist()\n",
    "f2=list(d)\n",
    "\n",
    "# list -> numpy\n",
    "g=np.asarray(f2)\n",
    "g=np.array(f2)\n",
    "print('f1:',type(f1))\n",
    "print('g:',type(g))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### long,int,double,float,byte类型转化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "float: torch.FloatTensor\n",
      "long: torch.LongTensor\n",
      "int: torch.IntTensor\n",
      "double: torch.DoubleTensor\n",
      "byte: torch.ByteTensor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(2,3,32,32)\n",
    "print(x.type())\n",
    "y = x.float()\n",
    "print(\"float:\",y.type())\n",
    "y = x.long()\n",
    "print(\"long:\",y.type())\n",
    "y = x.int()\n",
    "print(\"int:\",y.type())\n",
    "y = x.double()\n",
    "print(\"double:\",y.type())\n",
    "y = x.byte()\n",
    "print(\"byte:\",y.type())\n",
    "\n",
    "# # 一般只要在Tensor后加long(), int(), double(),float(),byte()等函数就能将Tensor进行类型转换；\n",
    "# 例如：Torch.LongTensor--->Torch.FloatTensor, 直接使用data.float()即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd: 自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "x + 2 = tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "(x + 2) grad_fn <AddBackward0 object at 0x7fe24c70eb70>\n",
      "x grad_fn None\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(\"x =\", x)\n",
    "y = x + 2\n",
    "print(\"x + 2 =\", y)\n",
    "print(\"(x + 2) grad_fn\", y.grad_fn)\n",
    "print(\"x grad_fn\",x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "x grad= tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)\n",
    "out.backward() ## out最好是标量\n",
    "## out = z\n",
    "## out.backward(torch.ones(out.shape))\n",
    "print(\"x grad=\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmentation(object):\n",
    "    def __init__(self, root, mode=None,shuffle=True, transform=None):\n",
    "        super(Segmentation, self).__init__()\n",
    "\n",
    "        self.images, self.masks = _get_pairs(root, mode,shuffle)\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.shuffle = shuffle\n",
    "        self.num_class = 5\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img = cv2.imread(self.images[index])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks[index],-1)\n",
    "        # general resize, normalize and to Tensor\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return torch.FloatTensor(img), torch.LongTensor(mask)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    @property\n",
    "    def pred_offset(self):\n",
    "        return 1\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        \"\"\"Category names.\"\"\"\n",
    "        return (\"0\",\"1\",\"2\",\"3\",\"4\")\n",
    "\n",
    "def _get_pairs(folder, mode='train', shuffle=True):\n",
    "\n",
    "    if mode == 'train':\n",
    "        img_folder = os.path.join(folder, '%d_imgs'%crop_size)\n",
    "        mask_folder = os.path.join(folder, '%d_label'%crop_size)\n",
    "    else:\n",
    "        img_folder = os.path.join(folder, '%d_imgs_val'%crop_size)\n",
    "        mask_folder = os.path.join(folder, '%d_label_val'%crop_size)\n",
    "\n",
    "    img_paths = glob(img_folder+\"/*\")\n",
    "    mask_paths = glob(mask_folder + \"/*\")\n",
    "    if shuffle:\n",
    "        img_paths = np.array(img_paths)\n",
    "        mask_paths = np.array(mask_paths)\n",
    "        index = [i for i in range(len(img_paths))]\n",
    "        np.random.shuffle(index)\n",
    "        img_paths = img_paths[index]\n",
    "        mask_paths = mask_paths[index]\n",
    "\n",
    "    return img_paths, mask_paths\n",
    "\n",
    "# dataset and dataloader\n",
    "input_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.2676, 0.2676, 0.2676], [0.180, 0.180, 0.180]),\n",
    "])\n",
    "data_kwargs = {'transform': input_transform}\n",
    "train_dataset = Segmentation(\"../zz\", mode='train',shuffle=True,**data_kwargs)\n",
    "val_dataset = Segmentation(\"../zz\", mode='val',shuffle=False,**data_kwargs)\n",
    "print(\"train_dataset :\",len(train_dataset))\n",
    "print(\"val_dataset:\",len(val_dataset))\n",
    "train_loader = data.DataLoader(dataset = train_dataset, batch_size= batch_size)\n",
    "val_loader = data.DataLoader(dataset = val_dataset, batch_size= batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5*5 square convolution\n",
    "        # kernel\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def weights_init(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.normal_(module.weight, mean = 0, std = 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "model = Net()\n",
    "print(model)\n",
    "model.weights_init()\n",
    "for module in model.modules():\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        weights = module.weight\n",
    "        weights = weights.reshape(-1).detach().cpu().numpy()\n",
    "        print(module.bias)                                       # Bias to zero\n",
    "        plt.hist(weights)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modules() vs children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing children\n",
      "------------------------------\n",
      "[Sequential(\n",
      "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Linear(in_features=10, out_features=2, bias=True)]\n",
      "\n",
      "\n",
      "Printing Modules\n",
      "------------------------------\n",
      "[myNet(\n",
      "  (convBN): Sequential(\n",
      "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (linear): Linear(in_features=10, out_features=2, bias=True)\n",
      "), Sequential(\n",
      "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1)), BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Linear(in_features=10, out_features=2, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "class myNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convBN =  nn.Sequential(nn.Conv2d(10,10,3), nn.BatchNorm2d(10))\n",
    "        self.linear =  nn.Linear(10,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "Net = myNet()\n",
    "# Net = myNet().half() ## 指定模型为半精度运行\n",
    "\n",
    "print(\"Printing children\\n------------------------------\")\n",
    "print(list(Net.children()))\n",
    "print(\"\\n\\nPrinting Modules\\n------------------------------\")\n",
    "print(list(Net.modules()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打印网络信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " myNet(\n",
      "  (convBN): Sequential(\n",
      "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (linear): Linear(in_features=10, out_features=2, bias=True)\n",
      ") \n",
      "-------------------------------\n",
      "convBN Sequential(\n",
      "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ") \n",
      "-------------------------------\n",
      "convBN.0 Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1)) \n",
      "-------------------------------\n",
      "convBN.1 BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) \n",
      "-------------------------------\n",
      "linear Linear(in_features=10, out_features=2, bias=True) \n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in Net.named_modules():\n",
    "  print(x[0], x[1], \"\\n-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不同的层设置不同的学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10,5)\n",
    "        self.fc2 = nn.Linear(5,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.fc1(x))\n",
    "\n",
    "Net = myNet()\n",
    "# optimiser = torch.optim.SGD(Net.parameters(), lr = 0.5)\n",
    "\n",
    "#######################################################################################################\n",
    "optimiser = torch.optim.SGD([{\"params\": Net.fc1.parameters(), 'lr' : 0.001, \"momentum\" : 0.99},\n",
    "                             {\"params\": Net.fc2.parameters()}], lr = 0.01, momentum = 0.9)\n",
    "\n",
    "\n",
    "#######################################################################################################\n",
    "params_bias = []\n",
    "params_wts = []\n",
    "# seperate the bias and weights parameters\n",
    "for name, parameter in Net.named_parameters():\n",
    "  if \"bias\" in name:\n",
    "    params_bias.append(parameter)\n",
    "  elif \"weight\" in name:\n",
    "    params_wts.append(parameter)\n",
    "\n",
    "# Set the optimiser to have different hyperparameters for bias and weights\n",
    "optimiser = torch.optim.SGD([{\"params\": params_bias, 'lr' : 0.001, \"momentum\" : 0.99},\n",
    "                             {\"params\": params_wts}], lr = 0.01, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 获得网络信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存和加载网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Net, \"net.pth\")\n",
    "Net = torch.load(\"net.pth\")\n",
    "print(Net)\n",
    "\n",
    "# Save and load only the model parameters (recommended).\n",
    "torch.save(resnet.state_dict(), 'params.ckpt')\n",
    "resnet.load_state_dict(torch.load('params.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获得网络的权重信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: conv1.weight torch.Size([6, 1, 5, 5])\n",
      "layer: conv1.bias torch.Size([6])\n",
      "layer: conv2.weight torch.Size([16, 6, 5, 5])\n",
      "layer: conv2.bias torch.Size([16])\n",
      "layer: fc1.weight torch.Size([120, 400])\n",
      "layer: fc1.bias torch.Size([120])\n",
      "layer: fc2.weight torch.Size([84, 120])\n",
      "layer: fc2.bias torch.Size([84])\n",
      "layer: fc3.weight torch.Size([10, 84])\n",
      "layer: fc3.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "model_dict = net.state_dict()\n",
    "for k,v in model_dict.items():\n",
    "    print(\"layer:\",k,v.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载网络预训练权重模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrainedweights(model, pretrained_model):\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(pretrained_model)\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "load_pretrainedweights(model,pretrained_model=\"model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查模型是否正确加载权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weight_loaded( ):\n",
    "\n",
    "    model =  EfficientNet_B4()\n",
    "    model_dict_v1 = model.state_dict()\n",
    "    model =  EfficientNet_B4()\n",
    "    model_dict_v2 = model.state_dict()\n",
    "    for k in model_dict_v1.keys():\n",
    "        try:\n",
    "            assert model_dict_v1[k].data.numpy().all() == model_dict_v2[k].data.numpy().all()\n",
    "        except AssertionError as e:\n",
    "            print(\"failed to load weights!\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"--> model weight loading is  successful!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型权重初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch.nn from init\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv')!=\"-1\":\n",
    "        init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('Linear')!=\"-1\":\n",
    "        init.normal(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d')!=\"-1\":\n",
    "        init.normal(m.weight.data, 1.0, 0.02)\n",
    "        init.constant(m.bias.data, 0.0)\n",
    "        \n",
    "model.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(weight_path, map_location=lambda storage, loc: storage))\n",
    "model.load_state_dict(torch.load(weight_path, map_location='cpu'))\n",
    "model = model.module#才是你的模型            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获得网络的中间某一层的输出和参数量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "            Conv2d-2           [-1, 16, 10, 10]           2,416\n",
      "            Linear-3                  [-1, 120]          48,120\n",
      "            Linear-4                   [-1, 84]          10,164\n",
      "            Linear-5                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(net)\n",
    "from torchsummary import summary\n",
    "summary(net,(1,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "print(\"model parameters device:\", next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the pretrained ResNet-18.\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "resnet = resnet18(pretrained=True)\n",
    "# If you want to finetune only the top layer of the model, set as below.\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the top layer for finetuning.\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n",
    "\n",
    "# Forward pass.\n",
    "images = torch.randn(64, 3, 224, 224)\n",
    "outputs = resnet(images)\n",
    "print (outputs.size())     # (64, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hook\n",
    "\n",
    "由于pytorch会自动舍弃图计算的中间结果，所以想要获取这些数值就需要使用钩子函数。\n",
    "钩子函数包括Variable的钩子和nn.Module钩子，用法相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### register_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "grad_list = []\n",
    "def print_grad(grad):\n",
    "    grad_list.append(grad)\n",
    "\n",
    "x = Variable(torch.ones(2, 1), requires_grad=True)\n",
    "y = x + 2\n",
    "z = torch.mean(torch.pow(y, 2))\n",
    "lr = 1e-3\n",
    "y.register_hook(print)\n",
    "y.register_hook(print_grad)\n",
    "z.backward()\n",
    "x.data -= lr * x.grad.data\n",
    "print(grad_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=160, out_features=5, bias=True)\n",
      "------------Input Grad------------\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "------------Output Grad------------\n",
      "torch.Size([5])\n",
      "\n",
      "\n",
      "Conv2d(3, 10, kernel_size=(2, 2), stride=(2, 2))\n",
      "------------Input Grad------------\n",
      "None found for Gradient\n",
      "torch.Size([10, 3, 2, 2])\n",
      "torch.Size([10])\n",
      "------------Output Grad------------\n",
      "torch.Size([1, 10, 4, 4])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "def hook_fn(m, i, o):\n",
    "    print(m)\n",
    "    print(\"------------Input Grad------------\")\n",
    "\n",
    "    for grad in i:\n",
    "        try:\n",
    "            print(grad.shape)\n",
    "        except AttributeError: \n",
    "            print (\"None found for Gradient\")\n",
    "\n",
    "    print(\"------------Output Grad------------\")\n",
    "    for grad in o:  \n",
    "        try:\n",
    "            print(grad.shape)\n",
    "        except AttributeError: \n",
    "            print (\"None found for Gradient\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "class myNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(3,10,2, stride = 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = lambda x: x.view(-1)\n",
    "        self.fc1 = nn.Linear(160,5)\n",
    "   \n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv(x))\n",
    "        return self.fc1(self.flatten(x))\n",
    "\n",
    "net = myNet()\n",
    "\n",
    "net.conv.register_backward_hook(hook_fn)\n",
    "net.fc1.register_backward_hook(hook_fn)\n",
    "inp = torch.randn(1,3,8,8)\n",
    "out = net(inp)\n",
    "(1 - out.mean()).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation = {}\n",
    "\n",
    "inp = torch.randn(1,3,8,8)\n",
    "\n",
    "def hook_fn(m, i, o):\n",
    "    visualisation[m] = o \n",
    "\n",
    "net = myNet()\n",
    "\n",
    "for name, layer in net._modules.items():\n",
    "    layer.register_forward_hook(hook_fn)\n",
    "\n",
    "out = net(inp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用的损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dice_loss(logits,true, eps=1e-7):\n",
    "    \"\"\"Computes the Sørensen–Dice loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the dice loss so we\n",
    "    return the negated dice loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "criterion = dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/60], Loss: 0.2952\n",
      "Epoch [10/60], Loss: 0.2376\n",
      "Epoch [15/60], Loss: 0.2142\n",
      "Epoch [20/60], Loss: 0.2047\n",
      "Epoch [25/60], Loss: 0.2008\n",
      "Epoch [30/60], Loss: 0.1991\n",
      "Epoch [35/60], Loss: 0.1984\n",
      "Epoch [40/60], Loss: 0.1981\n",
      "Epoch [45/60], Loss: 0.1979\n",
      "Epoch [50/60], Loss: 0.1978\n",
      "Epoch [55/60], Loss: 0.1977\n",
      "Epoch [60/60], Loss: 0.1976\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1:自定义损失函数\n",
    "def my_mse_loss(x, y):\n",
    "    return torch.mean(torch.pow((x - y), 2))\n",
    "\n",
    "## 2: 继承nn.Mdule\n",
    "class My_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return torch.mean(torch.pow((x - y), 2))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168],\n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042],\n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573],\n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827],\n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
    "\n",
    "# 将numpy数据转化为torch的张量\n",
    "inputs = torch.from_numpy(x_train)\n",
    "targets = torch.from_numpy(y_train)\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epochs = 60\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 第三步： 构建模型，构建一个一层的网络模型\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 与模型相关的配置、损失函数、优化方式\n",
    "# 使用自定义函数，等价于criterion = nn.MSELoss()\n",
    "criterion = My_loss()\n",
    "\n",
    "# 定义迭代优化算法， 使用的是随机梯度下降算法\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_history = []\n",
    "# 第四步：训练模型，迭代训练\n",
    "for epoch in range(num_epochs):\n",
    "    #  前向传播计算网络结构的输出结果\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 计算损失函数\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # 反向传播更新参数，三步策略，归零梯度——>反向传播——>更新参数\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 打印训练信息和保存loss\n",
    "    loss_history.append(loss.item())\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 第五步：结果展示。画出原y与x的曲线与网络结构拟合后的曲线\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()  # 模型输出结果\n",
    "\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')  # 原始数据\n",
    "plt.plot(x_train, predicted, label='Fitted line')  # 拟合之后的直线\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 画loss在迭代过程中的变化情况\n",
    "plt.plot(loss_history, label='loss for every epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLLLoss和CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0.3429,  0.9050, -2.3298],\n",
      "        [ 1.8048, -2.6157, -0.1287],\n",
      "        [ 0.0999, -1.1667,  0.7500],\n",
      "        [-0.6020, -0.1751,  0.4742]])\n",
      "softmax x: tensor([[0.3542, 0.6214, 0.0245],\n",
      "        [0.8645, 0.0104, 0.1251],\n",
      "        [0.3127, 0.0881, 0.5991],\n",
      "        [0.1829, 0.2804, 0.5367]])\n",
      "log: tensor([[-1.0379, -0.4759, -3.7107],\n",
      "        [-0.1456, -4.5660, -2.0790],\n",
      "        [-1.1624, -2.4289, -0.5123],\n",
      "        [-1.6986, -1.2716, -0.6224]])\n",
      "NLLLoss: tensor(1.7044)\n",
      "CrossEntropyLoss : tensor(1.7044)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "x=torch.randn(4,3)\n",
    "print(\"x:\", x)\n",
    "sm = nn.Softmax(dim =1)\n",
    "print(\"softmax x:\", sm(x))\n",
    "print(\"log:\", torch.log(sm(x)))\n",
    "\n",
    "loss = nn.NLLLoss()\n",
    "target = torch.tensor([0,2,1,1])\n",
    "print(\"NLLLoss:\",loss(torch.log(sm(x)),target))\n",
    "\n",
    "loss = nn.CrossEntropyLoss() # Softmax–Log–NLLLoss\n",
    "print(\"CrossEntropyLoss :\", loss(x, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCEWithLogitsLoss和BCELOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-1.1235, -0.0948, -0.8286],\n",
      "        [ 0.8362, -1.9370,  0.7749],\n",
      "        [ 1.1140, -0.2855,  1.0280]])\n",
      "Sigmoid x: tensor([[0.2454, 0.4763, 0.3039],\n",
      "        [0.6977, 0.1260, 0.6846],\n",
      "        [0.7529, 0.4291, 0.7365]])\n",
      "BCELoss : tensor(0.8267)\n",
      "CrossEntropyLoss : tensor(0.8267)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "x=torch.randn(3,3)\n",
    "print(\"x:\", x)\n",
    "sm = nn.Sigmoid()\n",
    "print(\"Sigmoid x:\", sm(x))\n",
    "\n",
    "\n",
    "target = torch.FloatTensor([[0,1,1],[1,0,0],[0,1,0]])\n",
    "loss = nn.BCELoss() # Sigmoid-BCELoss\n",
    "print(\"BCELoss :\", loss(sm(x), target))\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss() # Sigmoid-BCELoss\n",
    "print(\"CrossEntropyLoss :\", loss(x, target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常见的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict = output.argmax(dim = 1)\n",
    "confusion_matrix =torch.zeros(2,2)\n",
    "for p,t in zip(predict.view(-1), target.view(-1)):\n",
    "    confusion_matrix[t.long(), p.long()] += 1\n",
    "a_p =(confusion_matrix.diag() / confusion_matrix.sum(1))[0]\n",
    "b_p = (confusion_matrix.diag() / confusion_matrix.sum(1))[1]\n",
    "a_r =(confusion_matrix.diag() / confusion_matrix.sum(0))[0]\n",
    "b_r = (confusion_matrix.diag() / confusion_matrix.sum(0))[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用的优化器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                 lr=lr,\n",
    "                                 momentum=momentum,\n",
    "                                 weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用的学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr scheduling\n",
    "lr_scheduler = WarmupPolyLR(optimizer,\n",
    "                                 max_iters=epochs * iters_per_epoch,\n",
    "                                 power=0.9,\n",
    "                                 warmup_factor=warmup_factor,\n",
    "                                 warmup_iters=warmup_iters,\n",
    "                                 warmup_method=warmup_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimiser, milestones = [10,20], gamma = 0.1)\n",
    "scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, trian_dataset, val_dataset):\n",
    "    from tqdm import tqdm\n",
    "    from collections import deque\n",
    "    \n",
    "    train_loss = deque(maxlen=20)\n",
    "    \n",
    "    for epoch in range(1,n_epochs+1):\n",
    "    \n",
    "        model.train()\n",
    "        for index,(image,label) in tqdm(enumerate(trian_dataset)):\n",
    "            \n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "            model = model.to(device)\n",
    "            \n",
    "            train_preds = model(image)\n",
    "            loss_train = loss_fn(train_preds, label).to(device)\n",
    "            train_loss.append(loss_train.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss_train.backword()\n",
    "            optimizer.step()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        with torch.no_grad():\n",
    "            for index,(image,label) in tqdm(enumerate(val_dataset)):\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "                model = model.to(device)\n",
    "                \n",
    "                val_preds = model(image)\n",
    "                loss_val = loss_fn(val_preds, label).to(device)\n",
    "                val_loss.append(loss_val.item())\n",
    "        \n",
    "        print(\"\\nepoch:{:d}/{:d}, Lr:{:.6f},Loss:{:.4f},val_loss:{:.4f}\".\n",
    "          format(epoch, n_epochs+1, optimizer.param_groups[0]['lr'],np.mean(trian_loss), np.mean(val_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保持训练记录到csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_history = np.random.random(1000,6)\n",
    "x = pd.DataFrame(train_history)\n",
    "x.columns= ['Loss', 'val_loss', 'val_pixAcc', 'train_pixAcc', 'val_mIoU', 'train_mIoU']\n",
    "x.to_csv(\"./checkpoint/%s.csv\"%model_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 显示gpu\n",
    "!pip install gputil\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "gpu_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
